{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset Logistic Regression\n",
    "\n",
    "This notebook replicates the functionality of the `test.py` script, which trains a logistic regression model on the Iris dataset, evaluates it, and logs the experiment using MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Load the Iris dataset\n",
    "    X, y = datasets.load_iris(return_X_y=True)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    # Train the model\n",
    "    lr = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, y_pred\n",
    "\n",
    "\n",
    "def log_experiment(accuracy, model, X_train):\n",
    "    # Log the experiment\n",
    "    params = {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 1000,\n",
    "        \"multi_class\": \"auto\",\n",
    "        \"random_state\": 8888,\n",
    "    }\n",
    "    mlflow.set_experiment(\"Démarrage rapide MLflow\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.set_tag(\"Info_d_entrainement\", \"Modèle LR de base pour les données iris\")\n",
    "        signature = infer_signature(X_train, model.predict(X_train))\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"modele_iris\",\n",
    "            signature=signature,\n",
    "            input_example=X_train,\n",
    "            registered_model_name=\"demarrage-rapide-suivi\",\n",
    "        )\n",
    "    return model_info\n",
    "\n",
    "\n",
    "def load_and_predict(model_info, X_test, y_test):\n",
    "    # Load the model and make predictions\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "    predictions = loaded_model.predict(X_test)\n",
    "    iris_feature_names = datasets.load_iris().feature_names\n",
    "    result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "    result[\"actual_class\"] = y_test\n",
    "    result[\"predicted_class\"] = predictions\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, y_pred = evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'demarrage-rapide-suivi' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'demarrage-rapide-suivi'.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1169.91it/s]\n"
     ]
    }
   ],
   "source": [
    "model_info = log_experiment(accuracy, model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                6.1               2.8                4.7               1.2   \n",
      "1                5.7               3.8                1.7               0.3   \n",
      "2                7.7               2.6                6.9               2.3   \n",
      "3                6.0               2.9                4.5               1.5   \n",
      "\n",
      "   actual_class  predicted_class  \n",
      "0             1                1  \n",
      "1             0                0  \n",
      "2             2                2  \n",
      "3             1                1  \n"
     ]
    }
   ],
   "source": [
    "result = load_and_predict(model_info, X_test, y_test)\n",
    "print(result[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
